{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c7bfec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kiit\\anaconda3\\jupyter\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow\n",
    "!mkdir data\n",
    "!wget wget https://pjreddie.com/media/files/yolov3.weights -O data/yolov3.weights\n",
    "!wget https://pjreddie.com/media/files/yolov3-tiny.weights -O data/yolov3-tiny.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7309f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2, os, glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Add, Concatenate, Conv2D,\n",
    "    Input, Lambda, LeakyReLU,\n",
    "    MaxPool2D, UpSampling2D, ZeroPadding2D\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.losses import (\n",
    "    binary_crossentropy,\n",
    "    sparse_categorical_crossentropy\n",
    ")\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82a4301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLOV3_LAYER_LIST = [\n",
    "    'yolo_darknet',\n",
    "    'yolo_conv_0',\n",
    "    'yolo_output_0',\n",
    "    'yolo_conv_1',\n",
    "    'yolo_output_1',\n",
    "    'yolo_conv_2',\n",
    "    'yolo_output_2',\n",
    "]\n",
    "\n",
    "YOLOV3_TINY_LAYER_LIST = [\n",
    "    'yolo_darknet',\n",
    "    'yolo_conv_0',\n",
    "    'yolo_output_0',\n",
    "    'yolo_conv_1',\n",
    "    'yolo_output_1',\n",
    "]\n",
    "\n",
    "yolo_anchors = np.array([\n",
    "    (10, 13), (16, 30), (33, 23), (30, 61), (62, 45),\n",
    "    (59, 119), (116, 90), (156, 198), (373, 326)],\n",
    "    np.float32) / 416\n",
    "\n",
    "yolo_anchor_masks = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])\n",
    "\n",
    "yolo_tiny_anchors = np.array([\n",
    "    (10, 14), (23, 27), (37, 58),\n",
    "    (81, 82), (135, 169), (344, 319)],\n",
    "    np.float32) / 416\n",
    "\n",
    "yolo_tiny_anchor_masks = np.array([[3, 4, 5], [0, 1, 2]])\n",
    "\n",
    "class_names = [\n",
    "    'person', 'bicycle','car','motorbike','aeroplane','bus','train','truck','boat',\n",
    "    'traffic light','fire hydrant','stop sign','parking meter','bench',\n",
    "    'bird','cat','dog','horse','sheep','cow','elephant','bear','zebra',\n",
    "    'giraffe','backpack','umbrella','handbag','tie','suitcase','frisbee',\n",
    "    'skis','snowboard','sports ball','kite','baseball bat','baseball glove',\n",
    "    'skateboard','surfboard','tennis racket','bottle','wine glass','cup',\n",
    "    'fork','knife','spoon','bowl','banana','apple','sandwich','orange',\n",
    "    'broccoli','carrot','hot dog','pizza','donut','cake','chair','sofa',\n",
    "    'pottedplant','bed','diningtable','toilet','tvmonitor','laptop','mouse',\n",
    "    'remote','keyboard','cell phone','microwave','oven','toaster','sink',\n",
    "    'refrigerator','book','clock','vase','scissors','teddy bear',\n",
    "    'hair drier','toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b9ba0972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_darknet_weights(model, weights_file, input_shape, tiny=False):\n",
    "    wf = open(weights_file, 'rb')\n",
    "    major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
    "    if tiny:\n",
    "        layers = YOLOV3_TINY_LAYER_LIST\n",
    "    else:\n",
    "        layers = YOLOV3_LAYER_LIST\n",
    "    for layer_name in layers:\n",
    "        sub_model = model.get_layer(layer_name)\n",
    "        for i, layer in enumerate(sub_model.layers):\n",
    "            if not layer.name.startswith('conv2d'):\n",
    "                continue\n",
    "            batch_norm = None\n",
    "            if i + 1 < len(sub_model.layers) and sub_model.layers[i + 1].name.startswith('batch_norm'):\n",
    "                batch_norm = sub_model.layers[i + 1]\n",
    "            filters = layer.filters\n",
    "            size = layer.kernel_size[0]\n",
    "            if batch_norm is None:\n",
    "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
    "            else:\n",
    "                # darknet [beta, gamma, mean, variance]\n",
    "                bn_weights = np.fromfile(wf, dtype=np.float32, count=4 * filters)\n",
    "                # tf [gamma, beta, mean, variance]\n",
    "                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
    "            # darknet shape (out_dim, in_dim, height, width)\n",
    "            conv_shape = (filters, input_shape[-1], size, size)\n",
    "            conv_weights = np.fromfile(wf, dtype=np.float32, count=np.product(conv_shape))\n",
    "            # tf shape (height, width, in_dim, out_dim)\n",
    "            conv_weights = conv_weights.reshape(conv_shape).transpose([2, 3, 1, 0])\n",
    "            if batch_norm is None:\n",
    "                layer.set_weights([conv_weights, conv_bias])\n",
    "            else:\n",
    "                layer.set_weights([conv_weights])\n",
    "                batch_norm.set_weights(bn_weights)\n",
    "    assert len(wf.read()) == 0, 'failed to read all data'\n",
    "    wf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "850f6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_iou(box_1, box_2):\n",
    "    '''\n",
    "    box_1: (..., (x1, y1, x2, y2))\n",
    "    box_2: (N, (x1, y1, x2, y2))\n",
    "    '''\n",
    "\n",
    "    # broadcast boxes\n",
    "    box_1 = tf.expand_dims(box_1, -2)\n",
    "    box_2 = tf.expand_dims(box_2, 0)\n",
    "    # new_shape: (..., N, (x1, y1, x2, y2))\n",
    "    new_shape = tf.broadcast_dynamic_shape(tf.shape(box_1), tf.shape(box_2))\n",
    "    box_1 = tf.broadcast_to(box_1, new_shape)\n",
    "    box_2 = tf.broadcast_to(box_2, new_shape)\n",
    "    int_w = tf.maximum(tf.minimum(box_1[..., 2], box_2[..., 2]) - tf.maximum(box_1[..., 0], box_2[..., 0]), 0)\n",
    "    int_h = tf.maximum(tf.minimum(box_1[..., 3], box_2[..., 3]) - tf.maximum(box_1[..., 1], box_2[..., 1]), 0)\n",
    "    int_area = int_w * int_h\n",
    "    box_1_area = (box_1[..., 2] - box_1[..., 0]) * (box_1[..., 3] - box_1[..., 1])\n",
    "    box_2_area = (box_2[..., 2] - box_2[..., 0]) * (box_2[..., 3] - box_2[..., 1])\n",
    "    return int_area / (box_1_area + box_2_area - int_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ba528428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_all(model, frozen = True):\n",
    "    model.trainable = not frozen\n",
    "    if isinstance(model, tf.keras.Model):\n",
    "        for l in model.layers:\n",
    "            freeze_all(l, frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3d2fe8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_outputs(img, outputs, class_names):\n",
    "    boxes, objectness, classes, nums = outputs\n",
    "    boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]\n",
    "    wh = np.flip(img.shape[0:2])\n",
    "    for i in range(nums):\n",
    "        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
    "        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
    "        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\n",
    "        img = cv2.putText(img, '{} {:.4f}'.format(\n",
    "            class_names[int(classes[i])], objectness[i]),\n",
    "            x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "09db3089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_labels(x, y, class_names):\n",
    "    img = x.numpy()\n",
    "    boxes, classes = tf.split(y, (4, 1), axis = -1)\n",
    "    classes = classes[..., 0]\n",
    "    wh = np.flip(img.shape[0 : 2])\n",
    "    for i in range(len(boxes)):\n",
    "        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
    "        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
    "        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\n",
    "        img = cv2.putText(\n",
    "            img, class_names[classes[i]],\n",
    "            x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "            8, (0, 0, 255), 2\n",
    "        )\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6ff879b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_images(x_train, size):\n",
    "\tx_train = tf.image.resize(x_train, (size, size))\n",
    "\tx_train = x_train / 255\n",
    "\treturn x_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6569e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def transform_targets_for_output(y_true, grid_size, anchor_idxs, classes):\n",
    "    N = tf.shape(y_true)[0]\n",
    "    y_true_out = tf.zeros(\n",
    "        (N, grid_size, grid_size, tf.shape(anchor_idxs)[0], 6))\n",
    "    anchor_idxs = tf.cast(anchor_idxs, tf.int32)\n",
    "    indexes = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
    "    updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
    "    idx = 0\n",
    "    for i in tf.range(N):\n",
    "        for j in tf.range(tf.shape(y_true)[1]):\n",
    "            if tf.equal(y_true[i][j][2], 0):\n",
    "                continue\n",
    "            anchor_eq = tf.equal(\n",
    "                anchor_idxs, tf.cast(y_true[i][j][5], tf.int32))\n",
    "            if tf.reduce_any(anchor_eq):\n",
    "                box = y_true[i][j][0:4]\n",
    "                box_xy = (y_true[i][j][0:2] + y_true[i][j][2:4]) / 2\n",
    "                anchor_idx = tf.cast(tf.where(anchor_eq), tf.int32)\n",
    "                grid_xy = tf.cast(box_xy // (1/grid_size), tf.int32)\n",
    "                indexes = indexes.write(\n",
    "                    idx, [i, grid_xy[1], grid_xy[0], anchor_idx[0][0]])\n",
    "                updates = updates.write(\n",
    "                    idx, [box[0], box[1], box[2], box[3], 1, y_true[i][j][4]])\n",
    "                idx += 1\n",
    "    return tf.tensor_scatter_nd_update(\n",
    "        y_true_out, indexes.stack(), updates.stack())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "88c5dbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_targets(y_train, anchors, anchor_masks, classes):\n",
    "    y_outs = []\n",
    "    grid_size = 13\n",
    "    anchors = tf.cast(anchors, tf.float32)\n",
    "    anchor_area = anchors[..., 0] * anchors[..., 1]\n",
    "    box_wh = y_train[..., 2:4] - y_train[..., 0:2]\n",
    "    box_wh = tf.tile(tf.expand_dims(box_wh, -2), (1, 1, tf.shape(anchors)[0], 1))\n",
    "    box_area = box_wh[..., 0] * box_wh[..., 1]\n",
    "    intersection = tf.minimum(box_wh[..., 0], anchors[..., 0]) * tf.minimum(box_wh[..., 1], anchors[..., 1])\n",
    "    iou = intersection / (box_area + anchor_area - intersection)\n",
    "    anchor_idx = tf.cast(tf.argmax(iou, axis=-1), tf.float32)\n",
    "    anchor_idx = tf.expand_dims(anchor_idx, axis=-1)\n",
    "    y_train = tf.concat([y_train, anchor_idx], axis=-1)\n",
    "    for anchor_idxs in anchor_masks:\n",
    "        y_outs.append(transform_targets_for_output(\n",
    "            y_train, grid_size, anchor_idxs, classes))\n",
    "        grid_size *= 2\n",
    "    return tuple(y_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f64bf561",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization(tf.keras.layers.BatchNormalization):\n",
    "\n",
    "    def call(self, x, training = False):\n",
    "        if training is None:\n",
    "            traininig = tf.constant(False)\n",
    "        training = tf.logical_and(training, self.trainable)\n",
    "        return super().call(x, training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "658028fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DarknetConv(x, filters, size, strides=1, batch_norm=True):\n",
    "    if strides == 1:\n",
    "        padding = 'same'\n",
    "    else:\n",
    "        x = ZeroPadding2D(((1, 0), (1, 0)))(x)  # top left half-padding\n",
    "        padding = 'valid'\n",
    "    x = Conv2D(filters=filters, kernel_size=size,\n",
    "               strides=strides, padding=padding,\n",
    "               use_bias=not batch_norm, kernel_regularizer=l2(0.0005))(x)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4bd4ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DarknetResidual(x, filters):\n",
    "    prev = x\n",
    "    x = DarknetConv(x, filters // 2, 1)\n",
    "    x = DarknetConv(x, filters, 3)\n",
    "    x = Add()([prev, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3087f83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DarknetBlock(x, filters, blocks):\n",
    "    x = DarknetConv(x, filters, 3, strides=2)\n",
    "    for _ in range(blocks):\n",
    "        x = DarknetResidual(x, filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1113dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Darknet(name=None):\n",
    "    x = inputs = Input([None, None, 3])\n",
    "    x = DarknetConv(x, 32, 3)\n",
    "    x = DarknetBlock(x, 64, 1)\n",
    "    x = DarknetBlock(x, 128, 2)  # skip connection\n",
    "    x = x_36 = DarknetBlock(x, 256, 8)  # skip connection\n",
    "    x = x_61 = DarknetBlock(x, 512, 8)\n",
    "    x = DarknetBlock(x, 1024, 4)\n",
    "    return tf.keras.Model(inputs, (x_36, x_61, x), name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "df924f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DarknetTiny(name=None):\n",
    "    x = inputs = Input([None, None, 3])\n",
    "    x = DarknetConv(x, 16, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = DarknetConv(x, 32, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = DarknetConv(x, 64, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = DarknetConv(x, 128, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = x_8 = DarknetConv(x, 256, 3)  # skip connection\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = DarknetConv(x, 512, 3)\n",
    "    x = MaxPool2D(2, 1, 'same')(x)\n",
    "    x = DarknetConv(x, 1024, 3)\n",
    "    return tf.keras.Model(inputs, (x_8, x), name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "60c09d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YoloConv(filters, name=None):\n",
    "    def yolo_conv(x_in):\n",
    "        if isinstance(x_in, tuple):\n",
    "            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "            x, x_skip = inputs\n",
    "            # concat with skip connection\n",
    "            x = DarknetConv(x, filters, 1)\n",
    "            x = UpSampling2D(2)(x)\n",
    "            x = Concatenate()([x, x_skip])\n",
    "        else:\n",
    "            x = inputs = Input(x_in.shape[1:])\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "    return yolo_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0555f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YoloConvTiny(filters, name=None):\n",
    "    def yolo_conv(x_in):\n",
    "        if isinstance(x_in, tuple):\n",
    "            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "            x, x_skip = inputs\n",
    "            # concat with skip connection\n",
    "            x = DarknetConv(x, filters, 1)\n",
    "            x = UpSampling2D(2)(x)\n",
    "            x = Concatenate()([x, x_skip])\n",
    "        else:\n",
    "            x = inputs = Input(x_in.shape[1:])\n",
    "            x = DarknetConv(x, filters, 1)\n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "    return yolo_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "833b10b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YoloOutput(filters, anchors, classes, name=None):\n",
    "    def yolo_output(x_in):\n",
    "        x = inputs = Input(x_in.shape[1:])\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, anchors * (classes + 5), 1, batch_norm=False)\n",
    "        x = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2], anchors, classes + 5)))(x)\n",
    "        return tf.keras.Model(inputs, x, name=name)(x_in)\n",
    "    return yolo_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "87cafb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_boxes(pred, anchors, classes):\n",
    "    '''pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...classes))'''\n",
    "    grid_size = tf.shape(pred)[1]\n",
    "    box_xy, box_wh, objectness, class_probs = tf.split(\n",
    "        pred, (2, 2, 1, classes), axis=-1)\n",
    "    box_xy = tf.sigmoid(box_xy)\n",
    "    objectness = tf.sigmoid(objectness)\n",
    "    class_probs = tf.sigmoid(class_probs)\n",
    "    pred_box = tf.concat((box_xy, box_wh), axis=-1)  # original xywh for loss\n",
    "    grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)  # [gx, gy, 1, 2]\n",
    "    box_xy = (box_xy + tf.cast(grid, tf.float32)) / \\\n",
    "        tf.cast(grid_size, tf.float32)\n",
    "    box_wh = tf.exp(box_wh) * anchors\n",
    "    box_x1y1 = box_xy - box_wh / 2\n",
    "    box_x2y2 = box_xy + box_wh / 2\n",
    "    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n",
    "    return bbox, objectness, class_probs, pred_box\n",
    "\n",
    "def yolo_nms(outputs, anchors, masks, classes):\n",
    "    '''boxes, conf, type'''\n",
    "    b, c, t = [], [], []\n",
    "    for o in outputs:\n",
    "        b.append(tf.reshape(o[0], (tf.shape(o[0])[0], -1, tf.shape(o[0])[-1])))\n",
    "        c.append(tf.reshape(o[1], (tf.shape(o[1])[0], -1, tf.shape(o[1])[-1])))\n",
    "        t.append(tf.reshape(o[2], (tf.shape(o[2])[0], -1, tf.shape(o[2])[-1])))\n",
    "    bbox = tf.concat(b, axis=1)\n",
    "    confidence = tf.concat(c, axis=1)\n",
    "    class_probs = tf.concat(t, axis=1)\n",
    "    scores = confidence * class_probs\n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),\n",
    "        scores=tf.reshape(\n",
    "            scores,\n",
    "            (tf.shape(scores)[0], -1, tf.shape(scores)[-1])\n",
    "        ),\n",
    "        max_output_size_per_class=100,\n",
    "        max_total_size = 100,\n",
    "        iou_threshold = 0.5,\n",
    "        score_threshold = 0.5\n",
    "    )\n",
    "    return boxes, scores, classes, valid_detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b6c25bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YoloV3(size=None, channels=3, anchors=yolo_anchors, masks=yolo_anchor_masks, classes=80, training=False):\n",
    "    x = inputs = Input([size, size, channels])\n",
    "    x_36, x_61, x = Darknet(name='yolo_darknet')(x)\n",
    "    x = YoloConv(512, name='yolo_conv_0')(x)\n",
    "    output_0 = YoloOutput(512, len(masks[0]), classes, name='yolo_output_0')(x)\n",
    "    x = YoloConv(256, name='yolo_conv_1')((x, x_61))\n",
    "    output_1 = YoloOutput(256, len(masks[1]), classes, name='yolo_output_1')(x)\n",
    "    x = YoloConv(128, name='yolo_conv_2')((x, x_36))\n",
    "    output_2 = YoloOutput(128, len(masks[2]), classes, name='yolo_output_2')(x)\n",
    "    if training:\n",
    "        return Model(inputs, (output_0, output_1, output_2), name='yolov3')\n",
    "    boxes_0 = Lambda(lambda x: yolo_boxes(x, anchors[masks[0]], classes),\n",
    "                     name='yolo_boxes_0')(output_0)\n",
    "    boxes_1 = Lambda(lambda x: yolo_boxes(x, anchors[masks[1]], classes),\n",
    "                     name='yolo_boxes_1')(output_1)\n",
    "    boxes_2 = Lambda(lambda x: yolo_boxes(x, anchors[masks[2]], classes),\n",
    "                     name='yolo_boxes_2')(output_2)\n",
    "    outputs = Lambda(lambda x: yolo_nms(x, anchors, masks, classes),\n",
    "                     name='yolo_nms')((boxes_0[:3], boxes_1[:3], boxes_2[:3]))\n",
    "    return Model(inputs, outputs, name='yolov3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f200330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YoloV3Tiny(size=None, channels=3, anchors=yolo_tiny_anchors, masks=yolo_tiny_anchor_masks, classes=80, training=False):\n",
    "    x = inputs = Input([size, size, channels])\n",
    "    x_8, x = DarknetTiny(name='yolo_darknet')(x)\n",
    "    x = YoloConvTiny(256, name='yolo_conv_0')(x)\n",
    "    output_0 = YoloOutput(256, len(masks[0]), classes, name='yolo_output_0')(x)\n",
    "    x = YoloConvTiny(128, name='yolo_conv_1')((x, x_8))\n",
    "    output_1 = YoloOutput(128, len(masks[1]), classes, name='yolo_output_1')(x)\n",
    "    if training:\n",
    "        return Model(inputs, (output_0, output_1), name='yolov3')\n",
    "    boxes_0 = Lambda(lambda x: yolo_boxes(x, anchors[masks[0]], classes),\n",
    "                     name='yolo_boxes_0')(output_0)\n",
    "    boxes_1 = Lambda(lambda x: yolo_boxes(x, anchors[masks[1]], classes),\n",
    "                     name='yolo_boxes_1')(output_1)\n",
    "    outputs = Lambda(lambda x: yolo_nms(x, anchors, masks, classes),\n",
    "                     name='yolo_nms')((boxes_0[:3], boxes_1[:3]))\n",
    "    return Model(inputs, outputs, name='yolov3_tiny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "29a0e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YoloLoss(anchors, classes=80, ignore_thresh=0.5):\n",
    "    def yolo_loss(y_true, y_pred):\n",
    "        # 1. transform all pred outputs\n",
    "        # y_pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...cls))\n",
    "        pred_box, pred_obj, pred_class, pred_xywh = yolo_boxes(y_pred, anchors, classes)\n",
    "        pred_xy = pred_xywh[..., 0:2]\n",
    "        pred_wh = pred_xywh[..., 2:4]\n",
    "        # 2. transform all true outputs\n",
    "        # y_true: (batch_size, grid, grid, anchors, (x1, y1, x2, y2, obj, cls))\n",
    "        true_box, true_obj, true_class_idx = tf.split(\n",
    "            y_true, (4, 1, 1), axis=-1)\n",
    "        true_xy = (true_box[..., 0:2] + true_box[..., 2:4]) / 2\n",
    "        true_wh = true_box[..., 2:4] - true_box[..., 0:2]\n",
    "        # give higher weights to small boxes\n",
    "        box_loss_scale = 2 - true_wh[..., 0] * true_wh[..., 1]\n",
    "        # 3. inverting the pred box equations\n",
    "        grid_size = tf.shape(y_true)[1]\n",
    "        grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "        grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "        true_xy = true_xy * tf.cast(grid_size, tf.float32) - \\\n",
    "            tf.cast(grid, tf.float32)\n",
    "        true_wh = tf.math.log(true_wh / anchors)\n",
    "        true_wh = tf.where(tf.math.is_inf(true_wh), tf.zeros_like(true_wh), true_wh)\n",
    "        # 4. calculate all masks\n",
    "        obj_mask = tf.squeeze(true_obj, -1)\n",
    "        # ignore false positive when iou is over threshold\n",
    "        true_box_flat = tf.boolean_mask(true_box, tf.cast(obj_mask, tf.bool))\n",
    "        best_iou = tf.reduce_max(broadcast_iou(\n",
    "            pred_box, true_box_flat), axis=-1)\n",
    "        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
    "        # 5. calculate all losses\n",
    "        xy_loss = obj_mask * box_loss_scale * \\\n",
    "            tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n",
    "        wh_loss = obj_mask * box_loss_scale * \\\n",
    "            tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)\n",
    "        obj_loss = binary_crossentropy(true_obj, pred_obj)\n",
    "        obj_loss = obj_mask * obj_loss + \\\n",
    "            (1 - obj_mask) * ignore_mask * obj_loss\n",
    "        # Could also use binary_crossentropy instead\n",
    "        class_loss = obj_mask * sparse_categorical_crossentropy(\n",
    "            true_class_idx, pred_class)\n",
    "        # 6. sum over (batch, gridx, gridy, anchors) => (batch, 1)\n",
    "        xy_loss = tf.reduce_sum(xy_loss, axis=(1, 2, 3))\n",
    "        wh_loss = tf.reduce_sum(wh_loss, axis=(1, 2, 3))\n",
    "        obj_loss = tf.reduce_sum(obj_loss, axis=(1, 2, 3))\n",
    "        class_loss = tf.reduce_sum(class_loss, axis=(1, 2, 3))\n",
    "        return xy_loss + wh_loss + obj_loss + class_loss\n",
    "    return yolo_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "68449267",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[150], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m yolo_model \u001b[38;5;241m=\u001b[39m YoloV3()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load darknet weights into the YOLOv3 model \u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m load_darknet_weights(yolo_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mKIIT\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mPROJECTS\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mTRAFFIC CLASSIFICATION\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124myolov3.weights\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[89], line 28\u001b[0m, in \u001b[0;36mload_darknet_weights\u001b[1;34m(model, weights_file, input_shape, tiny)\u001b[0m\n\u001b[0;32m     26\u001b[0m     bn_weights \u001b[38;5;241m=\u001b[39m bn_weights\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m4\u001b[39m, filters))[[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# darknet shape (out_dim, in_dim, height, width)\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m conv_shape \u001b[38;5;241m=\u001b[39m (filters, input_shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], size, size)\n\u001b[0;32m     29\u001b[0m conv_weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfromfile(wf, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32, count\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mproduct(conv_shape))\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# tf shape (height, width, in_dim, out_dim)\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'bool' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Define or import your YOLOv3 model\n",
    "yolo_model = YoloV3()\n",
    "\n",
    "# Load darknet weights into the YOLOv3 model \n",
    "load_darknet_weights(yolo_model, 'C:\\\\Users\\\\KIIT\\\\Desktop\\\\PROJECTS\\\\TRAFFIC CLASSIFICATION\\\\yolov3.weights', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b2a899bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_file, model, class_names, visualize=True, figsize=(16, 16)):\n",
    "    # Load and preprocess the image\n",
    "    img = tf.image.decode_image(open(image_file, 'rb').read(), channels=3)\n",
    "    img = tf.expand_dims(img, 0)\n",
    "    img = transform_images(img, 416)\n",
    "    \n",
    "    # Perform prediction using the model\n",
    "    boxes, scores, classes, nums = model.predict(img)\n",
    "    \n",
    "    # Draw bounding boxes on the image\n",
    "    img = cv2.cvtColor(cv2.imread(image_file), cv2.COLOR_BGR2RGB)\n",
    "    img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\n",
    "    \n",
    "    # Visualize the image with bounding boxes\n",
    "    if visualize:\n",
    "        fig, axes = plt.subplots(figsize=figsize)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    \n",
    "    return boxes, scores, classes, nums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "283428d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = glob.glob('C:\\\\Users\\\\KIIT\\\\Desktop\\\\PROJECTS\\\\TRAFFIC CLASSIFICATION\\\\Screenshot 2024-04-28 173304.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d6438038",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "Exception encountered when calling BatchNormalization.call().\n\n\u001b[1mUsing a symbolic `tf.Tensor` as a Python `bool` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\u001b[0m\n\nArguments received by BatchNormalization.call():\n  • x=tf.Tensor(shape=(1, 416, 416, 32), dtype=float32)\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[149], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m boxes, scores, classes, nums \u001b[38;5;241m=\u001b[39m predict(image_file[\u001b[38;5;241m0\u001b[39m], yolo_model, class_names, visualize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m20\u001b[39m))\n",
      "Cell \u001b[1;32mIn[146], line 8\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(image_file, model, class_names, visualize, figsize)\u001b[0m\n\u001b[0;32m      5\u001b[0m img \u001b[38;5;241m=\u001b[39m transform_images(img, \u001b[38;5;241m416\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Perform prediction using the model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m boxes, scores, classes, nums \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(img)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Draw bounding boxes on the image\u001b[39;00m\n\u001b[0;32m     11\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(cv2\u001b[38;5;241m.\u001b[39mimread(image_file), cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n",
      "File \u001b[1;32m~\\anaconda3\\JUPYTER\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[128], line 7\u001b[0m, in \u001b[0;36mBatchNormalization.call\u001b[1;34m(self, x, training)\u001b[0m\n\u001b[0;32m      5\u001b[0m     traininig \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m training \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlogical_and(training, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcall(x, training)\n",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m: Exception encountered when calling BatchNormalization.call().\n\n\u001b[1mUsing a symbolic `tf.Tensor` as a Python `bool` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\u001b[0m\n\nArguments received by BatchNormalization.call():\n  • x=tf.Tensor(shape=(1, 416, 416, 32), dtype=float32)\n  • training=False"
     ]
    }
   ],
   "source": [
    "boxes, scores, classes, nums = predict(image_file[0], yolo_model, class_names, visualize=True, figsize=(20, 20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
